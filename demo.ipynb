{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43e582d6-d7ea-421b-ac58-945a3cfb385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "from munch import Munch\n",
    "from torch.backends import cudnn\n",
    "import torch\n",
    "\n",
    "from core.data_loader import get_train_loader\n",
    "from core.data_loader import get_test_loader\n",
    "from core.solver import Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ca0858-2952-4df1-af0b-e02da9e117d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5410, -0.2934, -2.1788])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cudnn.benchmark = True\n",
    "torch.manual_seed(0)\n",
    "torch.randn([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b107fba7-8fcc-45c6-8395-7c73ab8bdd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# model arguments\n",
    "parser.add_argument('--img_size', type=int, default=256,\n",
    "                    help='Image resolution')\n",
    "parser.add_argument('--num_domains', type=int, default=2,\n",
    "                    help='Number of domains')\n",
    "parser.add_argument('--latent_dim', type=int, default=16,\n",
    "                    help='Latent vector dimension')\n",
    "parser.add_argument('--hidden_dim', type=int, default=512,\n",
    "                    help='Hidden dimension of mapping network')\n",
    "parser.add_argument('--style_dim', type=int, default=64,\n",
    "                    help='Style code dimension')\n",
    "\n",
    "# weight for objective functions\n",
    "parser.add_argument('--lambda_reg', type=float, default=1,\n",
    "                    help='Weight for R1 regularization')\n",
    "parser.add_argument('--lambda_cyc', type=float, default=1,\n",
    "                    help='Weight for cyclic consistency loss')\n",
    "parser.add_argument('--lambda_sty', type=float, default=1,\n",
    "                    help='Weight for style reconstruction loss')\n",
    "parser.add_argument('--lambda_ds', type=float, default=2,\n",
    "                    help='Weight for diversity sensitive loss')\n",
    "parser.add_argument('--ds_iter', type=int, default=100000,\n",
    "                    help='Number of iterations to optimize diversity sensitive loss')\n",
    "parser.add_argument('--w_hpf', type=float, default=0,\n",
    "                    help='weight for high-pass filtering')\n",
    "\n",
    "# training arguments\n",
    "parser.add_argument('--randcrop_prob', type=float, default=0.5,\n",
    "                    help='Probabilty of using random-resized cropping')\n",
    "parser.add_argument('--total_iters', type=int, default=100000,\n",
    "                    help='Number of total iterations')\n",
    "parser.add_argument('--resume_iter', type=int, default=0,\n",
    "                    help='Iterations to resume training/testing')\n",
    "parser.add_argument('--batch_size', type=int, default=8,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--val_batch_size', type=int, default=32,\n",
    "                    help='Batch size for validation')\n",
    "parser.add_argument('--lr', type=float, default=1e-4,\n",
    "                    help='Learning rate for D, E and G')\n",
    "parser.add_argument('--f_lr', type=float, default=1e-6,\n",
    "                    help='Learning rate for F')\n",
    "parser.add_argument('--beta1', type=float, default=0.0,\n",
    "                    help='Decay rate for 1st moment of Adam')\n",
    "parser.add_argument('--beta2', type=float, default=0.99,\n",
    "                    help='Decay rate for 2nd moment of Adam')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                    help='Weight decay for optimizer')\n",
    "parser.add_argument('--num_outs_per_domain', type=int, default=10,\n",
    "                    help='Number of generated images per domain during sampling')\n",
    "\n",
    "# misc\n",
    "parser.add_argument('--mode', type=str,default='train', required=False,\n",
    "                    choices=['train', 'sample', 'eval', 'align'],\n",
    "                    help='This argument is used in solver')\n",
    "parser.add_argument('--num_workers', type=int, default=4,\n",
    "                    help='Number of workers used in DataLoader')\n",
    "parser.add_argument('--seed', type=int, default=777,\n",
    "                    help='Seed for random number generator')\n",
    "\n",
    "# directory for training\n",
    "parser.add_argument('--train_img_dir', type=str, default='data/afhq/train',\n",
    "                    help='Directory containing training images')\n",
    "parser.add_argument('--val_img_dir', type=str, default='data/afhq/val',\n",
    "                    help='Directory containing validation images')\n",
    "parser.add_argument('--sample_dir', type=str, default='expr/samples',\n",
    "                    help='Directory for saving generated images')\n",
    "parser.add_argument('--checkpoint_dir', type=str, default='expr/checkpoints',\n",
    "                    help='Directory for saving network checkpoints')\n",
    "\n",
    "# directory for calculating metrics\n",
    "parser.add_argument('--eval_dir', type=str, default='expr/eval',\n",
    "                    help='Directory for saving metrics, i.e., FID and LPIPS')\n",
    "\n",
    "# directory for testing\n",
    "parser.add_argument('--result_dir', type=str, default='expr/results',\n",
    "                    help='Directory for saving generated images and videos')\n",
    "parser.add_argument('--src_dir', type=str, default='assets/representative/afhq/src',\n",
    "                    help='Directory containing input source images')\n",
    "parser.add_argument('--ref_dir', type=str, default='assets/representative/afhq/ref',\n",
    "                    help='Directory containing input reference images')\n",
    "parser.add_argument('--inp_dir', type=str, default='assets/representative/custom/female',\n",
    "                    help='input directory when aligning faces')\n",
    "parser.add_argument('--out_dir', type=str, default='assets/representative/afhq/src/female',\n",
    "                    help='output directory when aligning faces')\n",
    "\n",
    "# face alignment\n",
    "parser.add_argument('--wing_path', type=str, default='expr/checkpoints/wing.ckpt')\n",
    "parser.add_argument('--lm_path', type=str, default='expr/checkpoints/celeba_lm_mean.npz')\n",
    "\n",
    "# step size\n",
    "parser.add_argument('--print_every', type=int, default=10)\n",
    "parser.add_argument('--sample_every', type=int, default=5000)\n",
    "parser.add_argument('--save_every', type=int, default=10000)\n",
    "parser.add_argument('--eval_every', type=int, default=50000)\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e60e49-f6d9-49de-8f9f-cc16fdf716ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=8, beta1=0.0, beta2=0.99, checkpoint_dir='expr/checkpoints', ds_iter=100000, eval_dir='expr/eval', eval_every=50000, f_lr=1e-06, hidden_dim=512, img_size=256, inp_dir='assets/representative/custom/female', lambda_cyc=1, lambda_ds=2, lambda_reg=1, lambda_sty=1, latent_dim=16, lm_path='expr/checkpoints/celeba_lm_mean.npz', lr=0.0001, mode='train', num_domains=2, num_outs_per_domain=10, num_workers=4, out_dir='assets/representative/afhq/src/female', print_every=10, randcrop_prob=0.5, ref_dir='assets/representative/afhq/ref', result_dir='expr/results', resume_iter=0, sample_dir='expr/samples', sample_every=5000, save_every=10000, seed=777, src_dir='assets/representative/afhq/src', style_dim=64, total_iters=100000, train_img_dir='data/afhq/train', val_batch_size=32, val_img_dir='data/afhq/val', w_hpf=0, weight_decay=0.0001, wing_path='expr/checkpoints/wing.ckpt')\n"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c47a364-792b-464e-ab77-bb13eeff6955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing DataLoader to fetch source images during the training phase...\n",
      "Preparing DataLoader to fetch reference images during the training phase...\n",
      "Preparing DataLoader for the generation phase...\n"
     ]
    }
   ],
   "source": [
    "loaders = Munch(src=get_train_loader(root=args.train_img_dir,\n",
    "                                     which='source',\n",
    "                                     img_size=args.img_size,\n",
    "                                     batch_size=args.batch_size,\n",
    "                                     prob=args.randcrop_prob,\n",
    "                                     num_workers=args.num_workers),\n",
    "                ref=get_train_loader(root=args.train_img_dir,\n",
    "                                     which='reference',\n",
    "                                     img_size=args.img_size,\n",
    "                                     batch_size=args.batch_size,\n",
    "                                     prob=args.randcrop_prob,\n",
    "                                     num_workers=args.num_workers),\n",
    "                val=get_test_loader(root=args.val_img_dir,\n",
    "                                    img_size=args.img_size,\n",
    "                                    batch_size=args.val_batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    num_workers=args.num_workers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef85da68-7c91-4e1a-b99b-fa67f953d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256]) torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for src in loaders.src:\n",
    "    src_demo = src[0]\n",
    "    print(src_demo.shape, src_demo.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67ff677-26aa-455b-ac96-a570b12f421c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256]) torch.Size([8, 3, 256, 256]) torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for ref in loaders.ref:\n",
    "    print(ref[0].shape, ref[1].shape, ref[2].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cd5cd0a-7afa-49ef-a9b3-4391cab81fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "batch_img = ((src_demo + 1)/2).clip(0, 1)\n",
    "save_image(batch_img.cpu(), './test.jpg', padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46caadc1-9d45-4440-b193-88b2fb192c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of generator: 33892995\n",
      "Number of parameters of mapping_network: 2438272\n",
      "Number of parameters of style_encoder: 20916928\n",
      "Number of parameters of discriminator: 20852290\n",
      "Initializing generator...\n",
      "Initializing mapping_network...\n",
      "Initializing style_encoder...\n",
      "Initializing discriminator...\n"
     ]
    }
   ],
   "source": [
    "solver = Solver(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4674b4ed-cc5f-4051-9695-0dab8ba5900c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 'expr/samples')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.sample_every, args.sample_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2cadc4e-5392-4dde-be4d-5798d3edf406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['generator', 'mapping_network', 'style_encoder', 'discriminator'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.nets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21b11cd-1bee-4be0-b4ae-28f4aa53d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernel.cu:93: operator(): block: [0,0,0], thread: [0,0,0] Assertion `index >= -sizes[i] && index < sizes[i] && \"index out of bounds\"` failed.\n"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "x = torch.rand([1, 3, 256, 256]).to('cuda:0')\n",
    "y = torch.randint(0, 3, [1]).to('cuda:0')\n",
    "dis = solver.nets.discriminator.to('cuda:0')\n",
    "dis_dot = make_dot(dis(x, y), params=dict(dis.named_parameters()), show_attrs=True, show_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ab9054-dd1c-4bcb-882c-9910505b92b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dis.pdf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unescaped left brace in regex is deprecated, passed through in regex; marked by <-- HERE in m/%{ <-- HERE (.*?)}/ at /usr/bin/run-mailcap line 528.\n",
      "Error: no \"view\" rule for type \"application/pdf\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "/usr/bin/xdg-open: line 778: www-browser: command not found\n",
      "/usr/bin/xdg-open: line 778: links2: command not found\n",
      "/usr/bin/xdg-open: line 778: elinks: command not found\n",
      "/usr/bin/xdg-open: line 778: links: command not found\n",
      "/usr/bin/xdg-open: line 778: lynx: command not found\n",
      "/usr/bin/xdg-open: line 778: w3m: command not found\n",
      "xdg-open: no method available for opening 'dis.pdf'\n"
     ]
    }
   ],
   "source": [
    "dis_dot.view(filename='dis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabd4b40-bc16-470d-bd24-a6dd7be43cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "map_net = solver.nets.mapping_network\n",
    "z = torch.rand([1, 16]).to('cuda:0') # latent code\n",
    "y = torch.randint(0, 3, [1]).to('cuda:0')\n",
    "map_net_dot = make_dot(map_net(z, y), params=dict(map_net.named_parameters()), show_attrs=True, show_saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91042e14-fe39-4f9b-97df-226fb050ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'map_net.pdf'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unescaped left brace in regex is deprecated, passed through in regex; marked by <-- HERE in m/%{ <-- HERE (.*?)}/ at /usr/bin/run-mailcap line 528.\n",
      "Error: no \"view\" rule for type \"application/pdf\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n",
      "/usr/bin/xdg-open: line 778: www-browser: command not found\n",
      "/usr/bin/xdg-open: line 778: links2: command not found\n",
      "/usr/bin/xdg-open: line 778: elinks: command not found\n",
      "/usr/bin/xdg-open: line 778: links: command not found\n",
      "/usr/bin/xdg-open: line 778: lynx: command not found\n",
      "/usr/bin/xdg-open: line 778: w3m: command not found\n",
      "xdg-open: no method available for opening 'map_net.pdf'\n"
     ]
    }
   ],
   "source": [
    "map_net_dot.view('map_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f6bba39-c16e-4d00-9b60-85ee224e0562",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn([1, 1024, 1,1])\n",
    "gamma, beta = torch.chunk(a, chunks=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcb50974-4196-4587-a92b-9c4222ea84a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512, 1, 1]), torch.Size([1, 512, 1, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.shape, beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f7017c-17cf-4890-8139-75712ba63d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
